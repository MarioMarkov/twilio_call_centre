{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunks:  5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "#from langchain_community.vectorstores import Chroma\n",
    "\n",
    "from langchain.text_splitter import CharacterTextSplitter,RecursiveCharacterTextSplitter\n",
    "\n",
    "load_dotenv()\n",
    "api_key  = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# current_dir = os.path.dirname( os.getcwd() )\n",
    "# print(\"Dir:\", current_dir)\n",
    "\n",
    "# Loading knowledge retriever\n",
    "loader = TextLoader(\"retrieval/about_you.txt\", encoding=\"UTF-8\")\n",
    "data = loader.load()\n",
    "# text_splitter = CharacterTextSplitter(\n",
    "#     separator=\"\\n\\n\",\n",
    "#     chunk_size=300,\n",
    "#     length_function=len\n",
    "# )\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "chunk_size=1000, chunk_overlap=0, separators=[\" \", \",\", \"\\n\"]\n",
    ")\n",
    "docs = text_splitter.split_documents(data)\n",
    "print(\"Chunks: \", len(docs))\n",
    "embedings_model = OpenAIEmbeddings(model = \"text-embedding-3-small\")\n",
    "\n",
    "db = FAISS.from_documents(docs,embedings_model)\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 1})\n",
    "\n",
    "from langchain.agents.agent_toolkits import create_retriever_tool\n",
    "\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"about_you_information\",\n",
    "    \"Searches and returns information about return and delivery questions for AboutYou.\",\n",
    ")\n",
    "tools = [retriever_tool]\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\",temperature=0,streaming=True)\n",
    "\n",
    "# Define prompt\n",
    "from langchain.prompts import MessagesPlaceholder\n",
    "from langchain.schema.messages import SystemMessage\n",
    "\n",
    "system_message = SystemMessage(\n",
    "    content=(\n",
    "        \"\"\"You are a voice call customer support bot for a bulgarian clothing store called AboutYou .\n",
    "Don't answer any questions outside of the domain of AboutYou custommer support.\n",
    "Always execute about_you_information tool.\n",
    "A user will call you and ask you questions about his delivery or return of a product.\n",
    "If you don't have the answer of the question in your knowledge say that you don't know, don't try to make up information.\n",
    "You give help to questions regarding the return and delivery of AboutYou items.\n",
    "Answer the questions briefly and summarize your information.\n",
    "Say maximum 3 sentances per answer.\n",
    "Аnswer the questions in bulgarian.\n",
    "\"\"\"\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "from langchain.agents.openai_functions_agent.base import OpenAIFunctionsAgent\n",
    "memory_key = \"chat_history\"\n",
    "prompt = OpenAIFunctionsAgent.create_prompt(\n",
    "    system_message=system_message,\n",
    "    extra_prompt_messages=[MessagesPlaceholder(variable_name=memory_key)],\n",
    ")\n",
    "\n",
    "# Define final Agent \n",
    "from langchain.agents import create_openai_functions_agent\n",
    "\n",
    "#agent = OpenAIFunctionsAgent(llm=llm, tools=tools, prompt=prompt)\n",
    "agent = create_openai_functions_agent(llm, tools, prompt)\n",
    "\n",
    "from langchain.agents import AgentExecutor\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    return_intermediate_steps=False,\n",
    "    #verbose=True\n",
    ")\n",
    "\n",
    "\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "message_history = ChatMessageHistory()\n",
    "message_history.clear()\n",
    "\n",
    "agent_with_chat_history = RunnableWithMessageHistory(\n",
    "    agent_executor,\n",
    "    lambda session_id: message_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=memory_key,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatMessageHistory(messages=[])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_with_chat_history.get_session_history(\"<foo>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'За да върнеш продукта си, постави го в оригиналната опаковка, приложи документа за връщане и залепи етикета за връщане. След това можеш да го изпратиш до най-близкия офис на Еконт или да поръчаш куриер.\\nАко си загубил документите за връщане, можеш да ги свалиш от клиентския си профил в ABOUT YOU и да ги използваш за връщане на продукта.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_with_chat_history.invoke({'input': 'как мога да си върна продукта'}, {'configurable': {'session_id': 'asd'}})['output']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langserve import RemoteRunnable\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "\n",
    "remote_agent = RemoteRunnable(\n",
    "    \"https://bot.happytree-937aa4bb.westus2.azurecontainerapps.io\"\n",
    ")\n",
    "message_history = ChatMessageHistory()\n",
    "message_history.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  langchain_core.messages.ai import AIMessageChunk\n",
    "async def get_tokens(input:str):\n",
    "    path_status = {}\n",
    "    async for chunk in agent_with_chat_history.astream_log(\n",
    "        {\"input\": input, \"chat_history\": message_history.messages},\n",
    "        config={\"configurable\": {\"session_id\": \"<foo>\"}},\n",
    "        include_names=[\"ChatOpenAI\"],\n",
    "    ):\n",
    "        for op in chunk.ops:\n",
    "            if op[\"op\"] == \"add\":\n",
    "                if op[\"path\"] not in path_status:\n",
    "                    path_status[op[\"path\"]] = op[\"value\"]\n",
    "                else:\n",
    "                    if not isinstance( op[\"value\"], dict):\n",
    "                        path_status[op[\"path\"]] += op[\"value\"]\n",
    "        if isinstance(path_status.get(op[\"path\"]), AIMessageChunk):\n",
    "            yield path_status.get(op[\"path\"]).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_history = ChatMessageHistory()\n",
    "message_history.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: model not found. Using cl100k_base encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaking : Връщането на продукт е лесно:\n",
      "1.\n",
      "Speaking :  Постави артикула в неговата оригинална опаковка.\n",
      "\n",
      "Speaking : \n",
      "2.\n",
      "Speaking :  Приложи документа за връщане и залепи етикета за връщане на пакета.\n",
      "\n",
      "Speaking : \n",
      "3.\n",
      "Speaking :  Занеси пакета до най-близкия офис на Еконт или поръчай куриер.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "pattern = re.compile(r'[.!?]')\n",
    "found = 0\n",
    "async for token in get_tokens(input=\"как мога да върна продукт\"):\n",
    "    sentence_ends = [match.start() for match in re.finditer(pattern, token)]\n",
    "    if len(sentence_ends) > found:\n",
    "        text = token[:sentence_ends[0] + 1] if found == 0 else token[sentence_ends[-2]+1 :]\n",
    "        print(\"Speaking :\", text)\n",
    "        found +=1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
